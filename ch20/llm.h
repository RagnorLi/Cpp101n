/**
 * @file llm.h
 * @author ragnor
 * @date 2025/3/24
 * @brief 
 * @details 
 * @copyright Copyright (c) 2025 ragnor. All rights reserved.
 */
#pragma once

namespace ch20 {
    void inferenceEnginesRuntimes_basicInferenceEngines();
    void inferenceEnginesRuntimes_largeModelSpecificEngines();
    void inferenceEnginesRuntimes_highPerformanceComputingLibraries();

    void quantizationOptimizationTools_modelQuantization();
    void quantizationOptimizationTools_memoryOptimization();
    void quantizationOptimizationTools_computationOptimization();

    void hardwareAccelerationInterfaces_gpuAcceleration();
    void hardwareAccelerationInterfaces_cpuOptimization();
    void hardwareAccelerationInterfaces_specializedAccelerators();

    void distributedTrainingInference_communicationLibraries();
    void distributedTrainingInference_distributedFrameworks();
    void distributedTrainingInference_orchestrationSystems();

    void modelIntegrationInterfaces_pythonEcosystemIntegration();
    void modelIntegrationInterfaces_webServiceInterfaces();
    void modelIntegrationInterfaces_crossLanguageInterfaces();

    void developmentDebuggingTools_profilingTools();
    void developmentDebuggingTools_debuggingTools();
    void developmentDebuggingTools_cicdTools();

    void practicalApplicationsCaseStudies_edgeDeviceDeployment();
    void practicalApplicationsCaseStudies_serverDeployment();
    void practicalApplicationsCaseStudies_verticalIndustryApplications();

    void performanceBenchmarksEvaluation_inferenceSpeed();
    void performanceBenchmarksEvaluation_memoryEfficiency();
    void performanceBenchmarksEvaluation_comparativeFrameworks();

    void run();
}
